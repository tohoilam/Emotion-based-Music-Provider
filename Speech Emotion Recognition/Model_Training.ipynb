{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76paNa0NCvvv",
        "outputId": "248f53f1-7e56-45ea-9886-e72f4aad0d8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version:   2.7.0\n",
            "TensorBoard version:  2.10.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from pydub import AudioSegment, effects\n",
        "from pydub.generators import WhiteNoise\n",
        "from pydub.playback import play\n",
        "from pydub.utils import mediainfo\n",
        "import librosa\n",
        "from librosa import display   \n",
        "import noisereduce as nr\n",
        "import IPython.display as ipd\n",
        "from IPython.display import Audio\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "import pytz\n",
        "import cv2\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorboard\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from json_tricks import dump, load\n",
        "\n",
        "from DataModel import DataModel\n",
        "from SERModel import SERModel\n",
        "from Evaluation import Evaluation\n",
        "\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"TensorFlow version:  \", tf.__version__)\n",
        "print(\"TensorBoard version: \", tensorboard.__version__)\n",
        "\n",
        "tz = pytz.timezone('Asia/Hong_Kong')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading and Extracting EmoDB Data...\n",
            "    Loaded and Extracted   407 data\n",
            "\n",
            "Data Extration Completed\n",
            "    Number of data: 407\n",
            "      Neutral     : 79\n",
            "      Frustration : 69\n",
            "      Anger       : 126\n",
            "      Sadness     : 62\n",
            "      Happiness   : 71\n",
            "      Excitement  : 0\n",
            "      Surprise    : 0\n",
            "      Disgust     : 0\n",
            "      Fear        : 0\n",
            "      Boredom     : 0\n",
            "\n",
            "Splitting data...\n",
            "Train Test Split Completed\n",
            "    Training Size : 326\n",
            "    Testing Size  : 81\n",
            "\n",
            "Split or Add Padding for training data:\n",
            "    Split Duration  : 8\n",
            "    Ignore Duration : 2\n",
            "Processing...\n",
            "    Processed   326 data split and padding\n",
            "Data Splitting and Padding For Training Completed!\n",
            "\n",
            "Processing training data to Mel Spectrogram...\n",
            "    Processed   326 Mel Spectrogram\n",
            "Mel Spectrogram Processing For Training Completed\n",
            "    Shape of training images: (326, 128, 251, 1)\n",
            "\n",
            "Processing training labels...\n",
            "Label Processing For Training Completed\n",
            "\n",
            "Split or Add Padding for testing data\n",
            "    Split Duration  : 8\n",
            "    Ignore Duration : 2\n",
            "Processing...\n",
            "    Processed    81 data split and padding\n",
            "Data Splitting and Padding For Testing Completed!\n",
            "\n",
            "Processing testing data to Mel Spectrogram...\n",
            "    Processed    81 Mel Spectrogram\n",
            "Mel Spectrogram Processing For Testing Completed\n",
            "    Shape of testing images: (81, 128, 251, 1)\n",
            "\n",
            "Processing testing labels...\n",
            "Label Processing For Testing Completed\n",
            "\n",
            "Data Processing Completed!\n",
            "  Data shapes:\n",
            "    x_train  : (326, 128, 251, 1)\n",
            "    y_train  : (326,)\n",
            "    sr_train : (326,)\n",
            "    x_test   : (81, 128, 251, 1)\n",
            "    y_test   : (81,)\n",
            "    sr_test  : (81,)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "labelsToInclude = ['Anger', 'Frustration', 'Happiness', 'Neutral',  'Sadness']\n",
        "mergeHappinessExcitement = True\n",
        "splitDuration = 8\n",
        "ignoreDuration = 2\n",
        "transformByStft=True\n",
        "hop_length = 512\n",
        "win_length = 2048\n",
        "n_mels = 128\n",
        "onehot = False\n",
        "\n",
        "# Data Augmentation Parameters\n",
        "# multiply = 3\n",
        "# pitchScaleSemitonesOffset=3.0\n",
        "# timeStretchOffset=0.2\n",
        "# randomGainOffset=0.2\n",
        "# addNoiseMaxFactor=0.2\n",
        "\n",
        "mixDataModel5LabelsSplit4Ignore2Stft = DataModel(labelsToInclude=labelsToInclude,\n",
        "                                                mergeHappinessExcitement=mergeHappinessExcitement,\n",
        "                                                splitDuration=splitDuration,\n",
        "                                                ignoreDuration=ignoreDuration,\n",
        "                                                transformByStft=transformByStft,\n",
        "                                                hop_length=hop_length,\n",
        "                                                win_length=win_length,\n",
        "                                                n_mels=n_mels,\n",
        "                                                onehot=onehot)\n",
        "# mixDataModel5LabelsSplit4Ignore2Stft.extractIEMOCAPData()\n",
        "mixDataModel5LabelsSplit4Ignore2Stft.extractEmoDBData()\n",
        "mixDataModel5LabelsSplit4Ignore2Stft.processData()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-01-20 02:26:37.778820: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "########################################################\n",
            "################### Training Section ###################\n",
            "########################################################\n",
            "\n",
            "Model Information:\n",
            "    Model Choice     : bestCNNModelLstmC\n",
            "    Experiment Name  : 01-20 02h26m37s jkl\n",
            "    Log Directory    : /Users/alexto/Documents/Programming/HKU/FYP/Speech Emotion Recognition/IEMOCAP_ModelLog/01-20 02h26m37s jkl\n",
            "    Result Directory : /Users/alexto/Documents/Programming/HKU/FYP/Speech Emotion Recognition/IEMOCAP_TrainedModel/01-20 02h26m37s jkl\n",
            "    Optimizer        : adam\n",
            "      Learning Rate  : 0.0001\n",
            "      Decay          : 0.001\n",
            "    Loss             : Sparse Categorical Crossentropy\n",
            "    Metrics          : Accuracy\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = SERModel('bestCNNModelLstmC', \"jkl\", input_shape=mixDataModel5LabelsSplit4Ignore2Stft.x_train[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 63, 125, 120)      1200      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 63, 125, 120)     480       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 62, 120)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 29, 60, 256)       276736    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 29, 60, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 30, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 12, 28, 512)       1180160   \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 12, 28, 512)      2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 14, 512)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 4, 12, 1024)       4719616   \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 4, 12, 1024)      4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 6, 1024)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 6, 2048)           0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              1081856   \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 9)                 585       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,276,057\n",
            "Trainable params: 7,272,233\n",
            "Non-trainable params: 3,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experiment 53"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def training53(dataModel, experimentName, modelName, epochs, early_stopping_patience, activation, optimizer, loss):\n",
        "  ySize = len(dataModel.labels_name)\n",
        "  learning_rate = 0.00005\n",
        "  decay = 0.0005\n",
        "  input_shape = dataModel.x_train[0].shape\n",
        "\n",
        "  cnnModel = SERModel(modelName,\n",
        "                      experimentName,\n",
        "                      ySize=ySize,\n",
        "                      optimizerChoice=optimizer,\n",
        "                      learning_rate=learning_rate,\n",
        "                      decay=decay,\n",
        "                      lossChoice=loss,\n",
        "                      input_shape=input_shape,\n",
        "                      activation=activation)\n",
        "  \n",
        "  history = cnnModel.fit(dataModel.x_train, dataModel.y_train, epochs, dataModel.validation_percent, early_stopping_patience=early_stopping_patience)\n",
        "  \n",
        "  evaluation = Evaluation(dataModel, cnnModel.resultDir, cnnModel.logDir, model=cnnModel.model)\n",
        "  evaluation.evaluateAllHistory(history)\n",
        "  \n",
        "  print('')\n",
        "  print('File Name: ' + cnnModel.logDir.split('/')[-1])\n",
        "\n",
        "  return evaluation\n",
        "\n",
        "experimentName = \"(Experiment53) Best CNN with LSTM (100 Epochs) (IEMOCAP EmoDB) (No Data Aug) (5 Emotions with Merge and Split 8 Ignore 2 STFT) (00005 lr 0005 decay Stop 3)\"\n",
        "modelName = \"bestCNNModelLstm\"\n",
        "epochs = 100\n",
        "early_stopping_patience = 3\n",
        "activation = 'relu'\n",
        "optimizer = 'adam'\n",
        "loss = 'scce'\n",
        "\n",
        "evaluation = training53(mixDataModel5LabelsSplit4Ignore2Stft, experimentName, modelName, epochs, early_stopping_patience, activation, optimizer, losse)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.8.3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
