{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76paNa0NCvvv",
        "outputId": "248f53f1-7e56-45ea-9886-e72f4aad0d8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version:   2.7.0\n",
            "TensorBoard version:  2.10.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from pydub import AudioSegment, effects\n",
        "from pydub.generators import WhiteNoise\n",
        "from pydub.playback import play\n",
        "from pydub.utils import mediainfo\n",
        "import librosa\n",
        "from librosa import display   \n",
        "import noisereduce as nr\n",
        "import IPython.display as ipd\n",
        "from IPython.display import Audio\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "import pytz\n",
        "import cv2\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorboard\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from json_tricks import dump, load\n",
        "\n",
        "from DataModel import DataModel\n",
        "from SERModel import SERModel\n",
        "from Evaluation import Evaluation\n",
        "\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"TensorFlow version:  \", tf.__version__)\n",
        "print(\"TensorBoard version: \", tensorboard.__version__)\n",
        "\n",
        "tz = pytz.timezone('Asia/Hong_Kong')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "########################################################\n",
            "################### Training Section ###################\n",
            "########################################################\n",
            "\n",
            "Model Information:\n",
            "    Model Choice     : optimal\n",
            "    Experiment Name  : 12-28 00h40m27s fjdslk\n",
            "    Log Directory    : /Users/alexto/Documents/Programming/HKU/FYP/Speech Emotion Recognition/IEMOCAP_ModelLog/12-28 00h40m27s fjdslk\n",
            "    Result Directory : /Users/alexto/Documents/Programming/HKU/FYP/Speech Emotion Recognition/IEMOCAP_TrainedModel/12-28 00h40m27s fjdslk\n",
            "    Optimizer        : Adam\n",
            "      Learning Rate  : 0.0001\n",
            "      Decay          : 0.001\n",
            "    Loss             : Sparse Categorical Crossentropy\n",
            "    Metrics          : Accuracy\n",
            "\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 128, 251, 32)      320       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 251, 32)      9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 64, 125, 32)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 125, 64)       18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 64, 125, 64)       36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 16, 31, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 31744)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               8126720   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 9)                 2313      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,194,025\n",
            "Trainable params: 8,194,025\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-28 00:40:28.011898: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "testing = SERModel(\"optimal\", \"fjdslk\")\n",
        "testing.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading and Extracting EmoDB Data...\n",
            "    Loaded and Extracted   408 data\n",
            "\n",
            "Data Extration Completed\n",
            "    Number of data: 408\n",
            "      Neutral     : 79\n",
            "      Frustration : 69\n",
            "      Anger       : 127\n",
            "      Sadness     : 62\n",
            "      Happiness   : 71\n",
            "      Excitement  : 0\n",
            "      Surprise    : 0\n",
            "      Disgust     : 0\n",
            "      Fear        : 0\n",
            "      Boredom     : 0\n",
            "\n",
            "Splitting data...\n",
            "Train Test Split Completed\n",
            "    Training Size : 327\n",
            "    Testing Size  : 81\n",
            "\n",
            "Split or Add Padding for training data:\n",
            "    Split Duration  : 8\n",
            "    Ignore Duration : 2\n",
            "Processing...\n",
            "    Processed   327 data split and padding\n",
            "Data Splitting and Padding For Training Completed!\n",
            "\n",
            "Processing training data to Mel Spectrogram...\n",
            "    Processed   327 Mel Spectrogram\n",
            "Mel Spectrogram Processing For Training Completed\n",
            "    Shape of training images: (327, 128, 251, 1)\n",
            "\n",
            "Processing training labels...\n",
            "Label Processing For Training Completed\n",
            "\n",
            "Split or Add Padding for testing data\n",
            "    Split Duration  : 8\n",
            "    Ignore Duration : 2\n",
            "Processing...\n",
            "    Processed    81 data split and padding\n",
            "Data Splitting and Padding For Testing Completed!\n",
            "\n",
            "Processing testing data to Mel Spectrogram...\n",
            "    Processed    81 Mel Spectrogram\n",
            "Mel Spectrogram Processing For Testing Completed\n",
            "    Shape of testing images: (81, 128, 251, 1)\n",
            "\n",
            "Processing testing labels...\n",
            "Label Processing For Testing Completed\n",
            "\n",
            "Data Processing Completed!\n",
            "  Data shapes:\n",
            "    x_train  : (327, 128, 251, 1)\n",
            "    y_train  : (327,)\n",
            "    sr_train : (327,)\n",
            "    x_test   : (81, 128, 251, 1)\n",
            "    y_test   : (81,)\n",
            "    sr_test  : (81,)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "labelsToInclude = ['Neutral', 'Frustration', 'Anger', 'Sadness', 'Happiness']\n",
        "mergeHappinessExcitement = True\n",
        "splitDuration = 8\n",
        "ignoreDuration = 2\n",
        "transformByStft=True\n",
        "hop_length = 512\n",
        "win_length = 2048\n",
        "n_mels = 128\n",
        "\n",
        "mixDataModel5LabelsSplit4Ignore2Stft = DataModel(labelsToInclude=labelsToInclude,\n",
        "                                                mergeHappinessExcitement=mergeHappinessExcitement,\n",
        "                                                splitDuration=splitDuration,\n",
        "                                                ignoreDuration=ignoreDuration,\n",
        "                                                transformByStft=transformByStft,\n",
        "                                                hop_length=hop_length,\n",
        "                                                win_length=win_length,\n",
        "                                                n_mels=n_mels)\n",
        "mixDataModel5LabelsSplit4Ignore2Stft.extractIEMOCAPData()\n",
        "mixDataModel5LabelsSplit4Ignore2Stft.extractEmoDBData()\n",
        "mixDataModel5LabelsSplit4Ignore2Stft.processData()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def trainingOptimal(dataModel, experimentName, modelName, epochs):\n",
        "  ySize = len(dataModel.labels_name)\n",
        "\n",
        "  cnnModel = SERModel(modelName, experimentName, ySize=ySize)\n",
        "  history = cnnModel.fit(dataModel.x_train, dataModel.y_train, epochs, dataModel.validation_percent)\n",
        "  \n",
        "  evaluation = Evaluation(dataModel, cnnModel.resultDir, cnnModel.logDir, model=cnnModel.model)\n",
        "  evaluation.evaluateAllHistory(history)\n",
        "  \n",
        "  print('')\n",
        "  print('File Name: ' + cnnModel.logDir.split('/')[-1])\n",
        "\n",
        "experimentName = \"(Experiment 16) CNN LSTM Model C (200 Epochs) (IEMOCAP EmoDB) (No Data Aug) (5 Emotions with Merge and Split 4 Ignore 2) (0001 lr 001 decay 32 batchsize)\"\n",
        "experimentName = \"Optimal\"\n",
        "modelName = \"optimal\"\n",
        "epochs = 200\n",
        "\n",
        "trainingOptimal(mixDataModel5LabelsSplit4Ignore2Stft, experimentName, modelName, epochs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.8.3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
